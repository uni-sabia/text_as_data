---
title: "Assignment 2"
output: html_document
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)
library(tidyverse)
library(tidytext)
library(readtext)
library(quanteda)
library(dplyr)
library(tidyr)
library(seededlda)
library(stm)
library(kableExtra)
theme_set(theme_minimal())
```


## Load and Prepare the data set

1. Load the `corpus_us_debate_speaker` from the data folder on the course's github repository main site, reshape the corpus into paragraphs and select only those paragraphs with at least 8 words in them. Create a tokens object in which words are converted to lower case and remove numbers, punctuation, common stop words, and tokens with less than two characters. Convert the tokens object to a dfm and trim it to include only tokens that appear at least in 7.5% of the documents and at most in 90% of the documents.

```{r}
# Load corpus
load("data/corpus_us_debate_speaker.rda") 
summary(corpus_us_debate_speaker, n=5)

# Reshape the corpus into paragraphs and subset 
speeches_para <- corpus_reshape(corpus_us_debate_speaker, to="paragraphs")
speeches_para <- corpus_subset(speeches_para, ntoken(speeches_para) >= 8)

table(ntoken(speeches_para))

# Create tokens object
para_tokens <- tokens(speeches_para,
                      remove_punct = TRUE,
                      remove_numbers = TRUE) %>%
  tokens_tolower() %>%
  tokens_remove(stopwords()) %>%
  tokens_select(min_nchar=2)

# Convert to dfm 
para_dfm <- dfm(para_tokens) 

para_dfm
```


2. Use the `convert()` function from `quanteda` to convert the dfm to an stm.

```{r, warning=FALSE}
para_stm <- convert(para_dfm,
        to="stm")
```

## Identify optimal number of topics

3. Fit five different structural topic models with different numbers of topics for $K$  = 10, 20, 30, 40, 50 respectively. Note that this might take a while to run and converge.

```{r, message=FALSE}

model1 <- stm(para_stm$documents,
              para_stm$vocab,
              verbose=FALSE,
              K=10)

model2 <- stm(para_stm$documents,
              para_stm$vocab,
              verbose=FALSE,
              K=20)

model3 <- stm(para_stm$documents,
              para_stm$vocab,
              verbose=FALSE,
              K=30)

model4 <- stm(para_stm$documents,
              para_stm$vocab,
              verbose=FALSE,
              K=40)

model5 <- stm(para_stm$documents,
              para_stm$vocab,
              verbose=FALSE,
              K=50)


```

4. Create a diagnostic plot showing the held-out likelihood, the residuals, the semantic coherence of the topics, and the lower bound. Also create a plot to contrast the semantic coherence with the exclusivity of the topics, i.e. how much each topic has its own vocabulary not used by other topics. Explain your results and decide on an optimal number of topics to continue with.

To choose the number of topics, we can consult several quantitative diagostic values by using `searchK()` function. I will choose K=30 and here's how I decided on this number: First, I ruled out k=50 because its residuals were too high. I ruled out k=10 because its held-out likelihood was the lowest. k=30 had the highest held-out likelihood than the rest. To be sure, I compared the semantic coherence vs. exclusivity graphs for k=20, 30, 40. Since k=30 had most points on the top-right, I will choose=30. 

```{r}
# Diagnostic Values 
search <- searchK(
  documents = para_stm$documents,
  vocab = para_stm$vocab,
  K = c(10, 20, 30, 40, 50),
  init.type="LDA",
  verbose=FALSE
)

plot(search)

# For k=30, 
# Check semantic coherence vs. exclusivity to check topic quality
coex <- function(k){
  model <- selectModel(para_stm$documents, 
            para_stm$vocab, 
            K = k, 
            data = para_stm$meta, seed = 8458159,
            verbose=FALSE,
            runs = 10
            )
  plotModels(model,
    xlab = "Semantic Coherence",
    ylab = "Exclusivity",
    labels = 1:length(model$runout),
    legend.position="bottomleft")
}

k_20 <- coex(k=20)
k_30 <- coex(k=30)
k_40 <- coex(k=40)

```

 > Notes: The Held-out likelihood estimates the probability of words appearing within a document when those words have been removed from the document (conditional probability). In other words, the higher the likelihood, the higher the model's prediction performance. Overdispersion of residuals indicates that more topics are needed to soak up the variance. Lastly, semantic coherence is maximized when the most probable words in a given topic frequently co-occur together. However, this could happen just by having a few topics dominated by very common words. To check the validity of this measure, we must contrast it with exclusivity, as shown in the second graph created using `plotModels()` function. 

## Create topic labels and explore topic prevalence

5. After you selected your preferred topic model (k=30), explore the word probabilities ($\beta$) and create meaningful labels for each topic. For some topics, identify documents that are very representative for a those particular topics. Discuss what some of your topics are about in a bit more detail.


```{r}
# For k=30
# Create a table of beta (word probabilities)
beta <- tidytext::tidy(model3)
beta

# Create a plot to compare beta across topics
beta_2 <- beta %>% group_by(topic) %>%
  top_n(10, beta) %>%
  ungroup() %>%
  mutate(term = reorder_within(term, beta, topic))
beta_2

ggplot(beta_2, aes(term, beta, fill = as.factor(topic))) +
  geom_col(alpha = 0.8, show.legend = FALSE) +
  facet_wrap(~ topic, scales = "free_y") +
  coord_flip() +
  scale_x_reordered() +
  labs(x = NULL, y = expression(beta),
       title = "Highest word probabilities for each topic",
       subtitle = "Different words are associated with different topics")

```

Let's create lables for each topic and see which topics are most prevalent. The following code tells us that topic 10, 5, 8 have the highest proportions. 

```{r}
labelTopics(model3, n=5)
plot.STM(model3, "summary")
```

Looking closer at topics 10, 5, 8, we get: 

```{r}
plot.STM(model3, "labels", topics=c(10, 5, 8), n=10,
         label="frex",  width=70)

```

To identify which documents are most representative of each topic, we use `findThoughts()` function. 

```{r}
thoughts <- function(model, texts, k) {
  findThoughts(
  model, texts= texts, topics=k)
}

thoughts10 <- thoughts(model3, speeches_para, 10)
thoughts5 <- thoughts(model3, speeches_para, 5)
thoughts8 <- thoughts(model3, speeches_para, 8)

```

## Topic 10: right, woman's, techniques, choose, dilation

The three documents that are most associated with topic 10 defend the Abortion Ban by arguing that a fetus is a child, and that abortion constitutes as "killing". 

```{r}
thoughts10
```

## Topic 5: procedures, safe, percent, medical, legal

The three documents that are most associated with topic 5 accuse that the high support for legalizing abortion is deceptive. 

```{r}
thoughts5
```

## Topic 8: baby, birth, partial, fetus, term 

The three documents that are most associated with topic 8 talk in gruesome detail about how dangerous abortion procedures are both to the mother and baby, and that abortion is like "killing" a child. 

```{r}
thoughts8
```


6. Extract the topic proportions ($\theta$) from the model and plot the prevalence of each topic across the overall corpus. Also create a perspective plot visualizing the combination of two topics and discuss the results.

The first plot from the code below shows the distribution of theta values per document. Since there are too many documents and topics, I only looked at first 15 documents and 10 topics. This plot shows topic proportion per document. Documents 2, 5, 6, 7 are strongly associated with topic 8. Other documents displayed in this plot are not strongly related to topics 1-10.

The second plot shows the prevalence of each topic across the corpus, which can be done using plot.STM function and "hist" as the "type" argument. Since 30 topics were too many to process, I only looked at 1 to 10 topics. This plot shows that each topic has very small relation with several documents. 

```{r}
# Topic proportions (=theta)
theta <- make.dt(model3)
theta

# Theta values per document
theta_2 <- tidy(model3, matrix="theta") %>% filter(
  document < 16, topic < 11) # Only look at first 15 documents and 10 topics because there are too many

theta_plot <- ggplot(theta_2, 
                     aes(y=gamma, x=as.factor(topic), fill = as.factor(topic))) +
  geom_bar(stat="identity",alpha = 0.8, show.legend = FALSE) +
  facet_wrap(~ document, ncol = 3) +
  labs(title = "Theta values per document",
       y = expression(theta), x = "Topic")
theta_plot

# Plot prevalence of each topic across the overall corpus (expected distribution of topic proportions across the documents)
plot.STM(model3, type="hist", topics=c(1:10))


```

Next three plots show the combination of two topics. The y-axis represents the frequency of words within the topic and x-axis represents how much the word is favored in the topic against each other. Overall, they show topical contrasts. These graphs show that topic 10 and 8 are highly contrasted, while topic 5 have weak semantic content.  

```{r}

# Combination of two topics
plot.STM(model3, type="perspectives", topics=c(10, 5))
plot.STM(model3, type="perspectives", topics=c(10, 8))
plot.STM(model3, type="perspectives", topics=c(8, 5))

```


## Fit an stm with covariates

7. Refit your favorite stm model but this time include a covariant for party affiliation into the model (i.e. saying that party affiliation impacts topic prevalence). Once the model converged, estimate the effect that party affiliation has on the prevalence of two topics, i.e. are Democrats or Republicans more likely to speak about either of the topics. Create a plot of your estimated effects and discuss your results.

The more republican the speaker is, the more likely she/he will talk about topic 8. This makes sense because topic 8 is contains strong arguments against abortion, including danger to the mother's health and baby's life, while Topic 10  discusses whether fetus can be considered as a child or not. However, party afflication does not play such a strong role because both topics are associated with anti-abortion sentiments, which are often favored by republicans.

```{r}
# k=30
model3_cov <- stm(para_stm$documents,
                  para_stm$vocab,
                  data=para_stm$meta,
                  K=30,
                  prevalence=~party,
                  verbose=FALSE) # Partu as a covariate in the topic prevalence argument

# Estimate the effect that party affiliation has on the prevalence of two topics
predict_topics <- estimateEffect(
  formula = 1:10 ~party, # first 10 topics
  stmobj= model3_cov,
  metadata= para_stm$meta,
  uncertainty = "Global"
)

plot(predict_topics,
     covariate="party",
     topics=c(10,8),
     model=model3_cov,
     method="difference",
     cov.value1 = "D", cov.value2="R",
     xlab = "More republican ................ More Democrat",
     main = "Effect of party on prevalence of two topics",
     xlim=c(-0.5,0.5),
     labeltype= "custom",
     custom.labels= c("Topic 10", "Topic 8")
     )


```


## Summarize

In this assignment, I performed structural topic modeling on a corpus of US public debates in the US, using `stm()` package. The goal of topic modeling is to discover topics in a text data and understand their relationship to metadata of documents. To perform the analysis, the optimal number of topics were identified by creating diagostic plots for the held-out likelihood, residuals, semantic coherence of topics and lower bounds for k=10, 20, 30, 40, 50. Among them, k=30 seemed most optimal for its high held-out likelihood, low residual and higher semantic coherence in comparison to exclusivity. 

Among the 30 topics, topic 10 (right, woman's, techniques, choose, dilation), 8 (procedures, safe, percent, medical, legal) and 5 (baby, birth, partial, fetus, term) had the highest expected topic proportions across documents. Each topic was labeled with top 5 terms with highest word probabilities. Details of each topic are discussed further in the main paragraph. Then, we analyzed the topic proportion (theta values) to see that documents 2, 5, 6, 7 are strongly associated with topic 8. Other documents were are not strongly related to topics 1-10. Also, all topics were not so prevalent, rather uniquely featured in a few documents. The two-topic contrast graphs showed that topic 10 and 8 are highly contrasted, while topic 5 have weak semantic content. Lastly, adding "party" as a covariate in the model showed that The more republican the speaker is, the more likely she/he will talk about topic 8, which contains strong arguments against abortion, including danger to the mother’s health and baby’s life. Party affliation does not play such a strong role because both topics 10 and 8 are associated with anti-abortion, which are both favored by republicans.
